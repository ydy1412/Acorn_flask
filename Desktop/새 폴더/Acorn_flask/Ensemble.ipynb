{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\siinn\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'numpy_array_data/Input5_data.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-bcc7a0c032a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mInput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'numpy_array_data/Input5_data.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mOutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'numpy_array_data/labels5_data.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'numpy_array_data/Input5_data.npy'"
     ]
    }
   ],
   "source": [
    "Input = np.load('numpy_array_data/Input5_data.npy')\n",
    "Output = np.load('numpy_array_data/labels5_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "senn = SMOTEENN(random_state=0)\n",
    "Oversampled_x, Oversampled_y = senn.fit_resample(Input, Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x's shape : (17523, 161)\n",
      "test_x's shape : (5842, 161)\n",
      "train_y's shape : (17523,)\n",
      "test_y's shape : (5842,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(Oversampled_x, Oversampled_y)\n",
    "print(\"train_x's shape :\", train_x.shape)\n",
    "print(\"test_x's shape :\", test_x.shape)\n",
    "print(\"train_y's shape :\", train_y.shape)\n",
    "print(\"test_y's shape :\", test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_target, y_pred):\n",
    "        # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "        # round : 반올림한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1))  # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1))  # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "        # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn)\n",
    "\n",
    "        # (True Positive + False Negative) = 실제 값이 1(Positive) 전체\n",
    "    count_true_positive_false_negative = K.sum(y_target_yn)\n",
    "\n",
    "        # Recall =  (True Positive) / (True Positive + False Negative)\n",
    "        # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
    "\n",
    "        # return a single tensor value\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision( y_target, y_pred):\n",
    "        # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "        # round : 반올림한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1))  # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1))  # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "        # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn)\n",
    "\n",
    "        # (True Positive + False Positive) = 예측 값이 1(Positive) 전체\n",
    "    count_true_positive_false_positive = K.sum(y_pred_yn)\n",
    "\n",
    "        # Precision = (True Positive) / (True Positive + False Positive)\n",
    "        # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n",
    "\n",
    "        # return a single tensor value\n",
    "    return precision\n",
    "\n",
    "def f1score(y_target, y_pred):\n",
    "    _recall = recall(y_target, y_pred)\n",
    "    _precision = precision(y_target, y_pred)\n",
    "        # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    _f1score = (2 * _recall * _precision) / (_recall + _precision + K.epsilon())\n",
    "\n",
    "        # return a single tensor value\n",
    "    return _f1score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuron Network Classifier Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_NN_model(hidden_layer=[30,30,30],init='he_normal') :\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_layer[0],input_shape=(161,)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    for layer in hidden_layer[1:]:\n",
    "        model.add(Dense(layer,init=init))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "    model.add(Dense(5,init=init))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\",recall,precision,f1score])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_NN_model,epochs=200,batch_size=10,verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init = ['glorot_uniform','normal','uniform']\n",
    "hidden_layers= [[30,30,30],[50,50,50,50],[70,70,70,70],[128,128,128,128]]\n",
    "param_grid = dict(hidden_layer = hidden_layers, init=init)\n",
    "NN_grid_model = GridSearchCV(estimator = model, param_grid = param_grid)\n",
    "NN_grid_model.fit(train_x,train_y)\n",
    "NN_best = NN_grid_model.best_estimator_\n",
    "NN_para = NN_best.best_params_\n",
    "with open(\"NN_best_para.pkl\",'wb') as f:\n",
    "    pickle.dump(NN_para,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = KFold(n_splits=10, shuffle = True, random_state = 0)\n",
    "\n",
    "RFC = RandomForestClassifier()\n",
    "rf_param_grid = {\"max_depth\" : [None],\n",
    "                 \"max_features\" : [3,8,8],\n",
    "                 \"min_samples_split\" : [2,3,8],\n",
    "                 \"bootstrap\" : [False],\n",
    "                 \"n_estimators\" : [100,300],\n",
    "                 \"criterion\" : ['gini'] }\n",
    "gsRFC = GridSearchCV(RFC,rf_param_grid,cv=k_fold, scoring = \"f1\",verbose=0)\n",
    "gsRFC.fit(train_x,train_y)\n",
    "RFC_best = gsRFC.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC = GradientBoostingClassifier()\n",
    "gb_param_grid = {\"loss\":['deviance'],\n",
    "                \"n_estimators\" : [100,200,300],\n",
    "                \"learning_rate\" : [0.1,0.05,0.01],\n",
    "                \"max_depth\" : [4,8],\n",
    "                \"min_samples_leaf\" : [100,150],\n",
    "                \"max_features\" :[0.3,0.1]}\n",
    "gsGBC = GridSearchCV(GBC,gb_param_grid,cv=k_fold, scoring = \"f1\",verbose=0)\n",
    "gsGBC.fit(train_x,train_y)\n",
    "GBC_best = gsRFC.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector classifier Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMC = SVC(probability=True)\n",
    "svc_param_grid = {\"kernel\":['rbf'],\n",
    "                \"gamma\" : [0.001,0.01,0.1,1],\n",
    "                \"C\" : [1,10,50,100,200,300,1000]}\n",
    "gsSVMC = GridSearchCV(SVMC,svc_param_grid,cv=k_fold, scoring = \"f1\",verbose=0)\n",
    "gsSVMC.fit(train_x,train_y)\n",
    "SVMC_best = gsRFC.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost classifier Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBC = XGBClassifier()\n",
    "xgb_param_grid = {\"max_depth\" : [3,5,7],\n",
    "                 \"min_child_weight\" : [3,5,6],\n",
    "                 \"gamma\" : [0,0.001,0.01,0.1,1],\n",
    "                 \"learning_rate\" : [0.1,0.05,0.01]}\n",
    "gsXGBC = GridSearchCV(XGBC,xgb_param_grid,cv=k_fold, scoring = \"f1\",verbose=0)\n",
    "gsXGBC.fit(train_x,train_y)\n",
    "XGBC_best = gsXGBC.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votingC = VotingClassifier(estimators = [(\"nnc\",NN_best),('rfc',RFC_best),(\"svc\",SVMC_best),('gbc',GBC_best),(\"xgb\",XGBC_best),\n",
    "                                        ],voting=\"soft\")\n",
    "votingC = votingC.fit(train_x,train_y)\n",
    "joblib.dump(obj,\"voting_classifier.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
